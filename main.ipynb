{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (2.3.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment              fallacy\n",
      "0  Lack of transparency in government isn't unexp...                 none\n",
      "1  While the issues discussed here should be addr...  appeal to authority\n",
      "2  The excuse that Brazilian municipalities do no...                 none\n",
      "3  This is what's to be expected of developing an...                 none\n",
      "4  Sad to say, I have to agree with you. Rulers c...  appeal to tradition\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the train dataset\n",
    "with open('cocolofa/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Extract relevant fields\n",
    "comments = []\n",
    "fallacies = []\n",
    "for article in train_data:\n",
    "    for comment in article['comments']:\n",
    "        comments.append(comment['comment'])\n",
    "        fallacies.append(comment['fallacy'])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'comment': comments, 'fallacy': fallacies})\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\n",
    "    {\"comment\": \"Katherine is a bad choice for mayor because she didn’t grow up in this town.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"You can’t trust John’s opinion on climate change because he’s not a scientist.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"Don’t listen to her advice on education reform; she dropped out of college.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"The CEO’s proposal is invalid because he only cares about making money.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"His argument on healthcare policy is irrelevant because he’s overweight.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"Why would we take financial advice from someone who went bankrupt?\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"Her stance on environmental issues is biased because she owns a gas station.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"Of course, he would say that—he’s been paid by the opposition.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"You shouldn't listen to her critique on art; she’s never painted anything herself.\", \"fallacy\": \"ad hominem\"},\n",
    "    {\"comment\": \"His thoughts on improving traffic systems are worthless since he doesn’t even drive.\", \"fallacy\": \"ad hominem\"}\n",
    "]\n",
    "\n",
    "# Append to DataFrame\n",
    "new_df = pd.DataFrame(new_data)\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Save updated dataset\n",
    "df.to_json('cocolofa/updated_train.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fallacy\n",
      "none                        2202\n",
      "slippery slope               431\n",
      "appeal to worse problems     421\n",
      "appeal to nature             412\n",
      "appeal to tradition          401\n",
      "false dilemma                391\n",
      "appeal to majority           383\n",
      "hasty generalization         379\n",
      "appeal to authority          350\n",
      "ad hominem                    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check Class Distribution\n",
    "print(df['fallacy'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in ./.venv/lib/python3.13/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in ./.venv/lib/python3.13/site-packages (from imbalanced-learn) (2.3.1)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in ./.venv/lib/python3.13/site-packages (from imbalanced-learn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in ./.venv/lib/python3.13/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in ./.venv/lib/python3.13/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in ./.venv/lib/python3.13/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in ./.venv/lib/python3.13/site-packages (from imbalanced-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "fallacy\n",
      "none                        2202\n",
      "appeal to authority         2202\n",
      "appeal to tradition         2202\n",
      "appeal to worse problems    2202\n",
      "hasty generalization        2202\n",
      "slippery slope              2202\n",
      "false dilemma               2202\n",
      "appeal to majority          2202\n",
      "appeal to nature            2202\n",
      "ad hominem                  2202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Perform oversampling to balance classes\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(df[['comment']], df['fallacy'])\n",
    "\n",
    "# Create a new balanced DataFrame\n",
    "balanced_df = pd.DataFrame({'comment': X_resampled['comment'], 'fallacy': y_resampled})\n",
    "\n",
    "# Check class distribution after oversampling\n",
    "print(balanced_df['fallacy'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"none\" fallacies\n",
    "df = df[df['fallacy'] != 'none']\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['comment'], df['fallacy'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['ad hominem' 'appeal to authority' 'appeal to majority'\n",
      " 'appeal to nature' 'appeal to tradition' 'appeal to worse problems'\n",
      " 'false dilemma' 'hasty generalization' 'slippery slope']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "print(\"Classes:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyurim/FallacyHunter/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LogicalFallacyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = LogicalFallacyDataset(train_encodings, train_labels_encoded)\n",
    "val_dataset = LogicalFallacyDataset(val_encodings, val_labels_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model and Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ew' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mew\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'ew' is not defined"
     ]
    }
   ],
   "source": [
    "ew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_fallacy\u001b[39m(sentence):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "trainer.evaluate()\n",
    "\n",
    "# Predict\n",
    "def predict_fallacy(sentence):\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    outputs = model(**tokens)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return label_encoder.inverse_transform([prediction])[0]\n",
    "\n",
    "#show the accuracy\n",
    "print(\"Accuracy:\", (trainer.evaluate()['eval_loss']))\n",
    "\n",
    "\n",
    "# Example prediction\n",
    "test_sentence = \"\"\"\n",
    "If we legalize marijuana, it might seem harmless at first. But over time, society could start accepting more dangerous drugs. \n",
    "Think about how alcohol was once banned, and now it's widely available despite its negative effects. Legalizing marijuana \n",
    "could pave the way for other drugs like cocaine or heroin to be considered acceptable, leading to widespread addiction and \n",
    "eventually the collapse of public health systems. We need to think carefully before taking such a risky step.\n",
    "\"\"\"\n",
    "\n",
    "print(test_sentence)\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))\n",
    "print(\"=====================================\")\n",
    "\n",
    "\n",
    "\n",
    "test_sentence = \"If we legalize marijuana, next thing you know, people will want to legalize harder drugs like cocaine or heroin, and society will spiral into chaos.\"\n",
    "print(\"If we legalize marijuana, next thing you know, people will want to legalize harder drugs like cocaine or heroin, and society will spiral into chaos.\")\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))\n",
    "print(\"=====================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recycling programs might seem beneficial, but they divert resources and focus from more pressing issues like global poverty and famine. While we’re busy sorting waste, millions of people are starving every day. Surely, as a society, our priorities should be on saving lives rather than debating about bins.\n",
      "Predicted Fallacy: appeal to worse problems\n",
      "Correct Fallacy is Appeal to worse \n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example prediction\n",
    "test_sentence = \"Recycling programs might seem beneficial, but they divert resources and focus from more pressing issues like global poverty and famine. While we’re busy sorting waste, millions of people are starving every day. Surely, as a society, our priorities should be on saving lives rather than debating about bins.\"\n",
    "\n",
    "\n",
    "print(test_sentence)\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))\n",
    "print(\"Correct Fallacy is Appeal to worse \")\n",
    "\n",
    "print(\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Fallacy: slippery slope\n",
      "Expected Fallacy: slippery slope\n",
      "=====================================\n",
      "Predicted Fallacy: appeal to worse problems\n",
      "Expected Fallacy: appeal to worse problems\n",
      "=====================================\n",
      "Predicted Fallacy: appeal to nature\n",
      "Expected Fallacy: appeal to nature\n",
      "=====================================\n",
      "Predicted Fallacy: appeal to tradition\n",
      "Expected Fallacy: appeal to tradition\n",
      "Expected Fallacy: appeal to tradition\n",
      "=====================================\n",
      "Predicted Fallacy: false dilemma\n",
      "Expected Fallacy: false dilemma\n",
      "=====================================\n",
      "Predicted Fallacy: appeal to majority\n",
      "Expected Fallacy: appeal to majority\n",
      "=====================================\n",
      "Predicted Fallacy: hasty generalization\n",
      "Expected Fallacy: hasty generalization\n",
      "=====================================\n",
      "Predicted Fallacy: appeal to authority\n",
      "Expected Fallacy: appeal to authority\n"
     ]
    }
   ],
   "source": [
    "# Slippery Slope\n",
    "test_sentence = \"If we ban cars, we’ll soon ban planes, and eventually, we’ll all be walking everywhere!\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: slippery slope\n",
    "print(\"Expected Fallacy:\", \"slippery slope\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Appeal to Worse Problems\n",
    "test_sentence = \"Why worry about plastic pollution when we have much bigger problems like world hunger?\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: appeal to worse problems\n",
    "print(\"Expected Fallacy:\", \"appeal to worse problems\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Appeal to Nature\n",
    "test_sentence = \"Eating organic food is better because it’s natural and free from artificial chemicals.\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: appeal to nature\n",
    "print(\"Expected Fallacy:\", \"appeal to nature\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Appeal to Tradition\n",
    "test_sentence = \"We should continue this practice because it has been done this way for centuries.\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: appeal to tradition\n",
    "print(\"Expected Fallacy:\", \"appeal to tradition\")\n",
    "print(\"Expected Fallacy:\", \"appeal to tradition\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# False Dilemma\n",
    "test_sentence = \"You’re either with us, or you’re against us—there’s no middle ground.\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: false dilemma\n",
    "print(\"Expected Fallacy:\", \"false dilemma\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Appeal to Majority\n",
    "test_sentence = \"Most people believe this is true, so it must be right.\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: appeal to majority\n",
    "print(\"Expected Fallacy:\", \"appeal to majority\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Hasty Generalization\n",
    "test_sentence = \"My neighbor doesn’t recycle, so no one in this town cares about the environment.\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: hasty generalization\n",
    "print(\"Expected Fallacy:\", \"hasty generalization\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Appeal to Authority\n",
    "test_sentence = \"This diet must be effective because a famous doctor endorses it.\"\n",
    "print(\"Predicted Fallacy:\", predict_fallacy(test_sentence))  # Expected: appeal to authority\n",
    "print(\"Expected Fallacy:\", \"appeal to authority\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model/tokenizer_config.json',\n",
       " './saved_model/special_tokens_map.json',\n",
       " './saved_model/vocab.txt',\n",
       " './saved_model/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"./saved_model\")\n",
    "tokenizer.save_pretrained(\"./saved_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
